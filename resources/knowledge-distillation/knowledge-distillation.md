## Knowledge Distillation

**Legend**  
:baby: Abstracted Quick/Easy Information  
:mortar_board: Advanced/In-Depth Material

#### Papers

* :mortar_board: [Original Paper](https://arxiv.org/pdf/1503.02531.pdf) by Hinton et al. (2015).
* :mortar_board: [SOTA on ImageNet](https://arxiv.org/abs/1911.04252) by Google Research
* :mortar_board: [Combination with the self-supervised paradigm](https://arxiv.org/pdf/2006.10029.pdf) by Google Research
* :mortar_board: [Attention Distillation](https://arxiv.org/abs/1612.03928) from ICLR
#### Articles
* :baby: [Simple explanation of the ideas behind KD](https://ramesharvind.github.io/posts/deep-learning/knowledge-distillation/)

#### Videos
* :baby: [Simple implementation of KD for vision in TF/keras](https://youtu.be/Y2K13XDqwiM) by Henry AI Labs
